{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bedebb1-abf3-44a4-aeb5-7f1abd68af46",
   "metadata": {},
   "source": [
    "***1- Data Management.*** <br>\n",
    "https://dvc.org/doc/start\n",
    "***\n",
    "\n",
    "1- Initializee the dvc repository. <br>\n",
    "2- commit what we did so far. <br>\n",
    "3- download the data with dvc get wrapper. <br>\n",
    "4- add data to dvc tracking. this line will create a file with same name as our data with .dvc format and also a .gitignore file. <br>\n",
    "5- add the tracking data and git placeholder with git command. <br>\n",
    "6- create the remote locally or online. add the remote as a dvc remote. <br>\n",
    "7- push the data using dvc order and follow by a git commit to save the version control. <br>\n",
    "8- change between different version of the model and data. <br>\n",
    "9- just use these codes to add and commit new modified datasets. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc3d978a-135f-4a59-952a-df6c7cea19fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized DVC repository.\n",
      "\n",
      "You can now commit the changes to git.\n",
      "\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m        DVC has enabled anonymous aggregate usage analytics.         \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m     Read the analytics documentation (and how to opt-out) here:     \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m             <\u001b[36mhttps://dvc.org/doc/user-guide/analytics\u001b[39m>              \u001b[31m|\u001b[0m\n",
      "\u001b[31m|\u001b[0m                                                                     \u001b[31m|\u001b[0m\n",
      "\u001b[31m+---------------------------------------------------------------------+\n",
      "\u001b[0m\n",
      "\u001b[33mWhat's next?\u001b[39m\n",
      "\u001b[33m------------\u001b[39m\n",
      "- Check out the documentation: <\u001b[36mhttps://dvc.org/doc\u001b[39m>\n",
      "- Get help and share ideas: <\u001b[36mhttps://dvc.org/chat\u001b[39m>\n",
      "- Star us on GitHub: <\u001b[36mhttps://github.com/iterative/dvc\u001b[39m>\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! dvc init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af9dbb9e-8028-4fb9-a738-5f0dbfeb22ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is up to date with 'origin/master'.\n",
      "\n",
      "Changes to be committed:\n",
      "  (use \"git restore --staged <file>...\" to unstage)\n",
      "\t\u001b[32mnew file:   .dvc/.gitignore\u001b[m\n",
      "\t\u001b[32mnew file:   .dvc/config\u001b[m\n",
      "\t\u001b[32mnew file:   .dvcignore\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31mMLOPs.ipynb\u001b[m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd083ae9-9c6e-4254-a729-10b2391deb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master d9730c7] Initialize DVC\n",
      " 3 files changed, 6 insertions(+)\n",
      " create mode 100644 .dvc/.gitignore\n",
      " create mode 100644 .dvc/config\n",
      " create mode 100644 .dvcignore\n",
      "\u001b[0m                                                                            "
     ]
    }
   ],
   "source": [
    "! git commit -m \"Initialize DVC\"\n",
    "# download the data and save it in a new folder\n",
    "! dvc get https://github.com/iterative/dataset-registry \\\n",
    "          get-started/data.xml -o data/data.xml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cded522b-e5a9-4fdb-a04d-0cedfcab65c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[32m⠋\u001b[0m Checking graph                                       core\u001b[39m>\n",
      "Adding...                                                                       \n",
      "!\u001b[A\n",
      "Collecting files and computing hashes in data/data.xml |0.00 [00:00,     ?file/s\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/home/ali/NPEMF/.dvc/cache/files/md5'| |0/? [00:00<?,   \u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Adding data/data.xml to cache         0/1 [00:00<?,     ?file/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "!\u001b[A\n",
      "  0%|          |Checking out /home/ali/NPEMF/data/data0/1 [00:00<?,    ?files/s]\u001b[A\n",
      "100% Adding...|████████████████████████████████████████|1/1 [00:00, 13.18file/s]\u001b[A\n",
      "\n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add data/.gitignore data/data.xml.dvc\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! dvc add data/data.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9005369c-ca9d-46a1-b18d-09213de493fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 3560319] Add raw data\n",
      " 2 files changed, 6 insertions(+)\n",
      " create mode 100644 data/.gitignore\n",
      " create mode 100644 data/data.xml.dvc\n"
     ]
    }
   ],
   "source": [
    "! git add data/data.xml.dvc data/.gitignore\n",
    "! git commit -m \"Add raw data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32b7d13a-281a-4a0a-842a-effb83cd3aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting 'myremote' as a default remote.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# local storage\n",
    "! mkdir /tmp/dvcstore\n",
    "! dvc remote add -d myremote /tmp/dvcstore\n",
    "\n",
    "# remote storage\n",
    "# ! dvc remote add -d storage s3://mybucket/dvcstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94018a3a-a1a4-4720-8203-8756794cb87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting                                            |1.00 [00:00,  179entry/s]\n",
      "Pushing\n",
      "!\u001b[A\n",
      "  0% Checking cache in '/tmp/dvcstore/files/md5'|    |0/? [00:00<?,    ?files/s]\u001b[A\n",
      "Pushing                                                                         \u001b[A\n",
      "Everything is up to date.\n",
      "\u001b[0mOn branch master\n",
      "Your branch is ahead of 'origin/master' by 2 commits.\n",
      "  (use \"git push\" to publish your local commits)\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mmodified:   .dvc/config\u001b[m\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m.ipynb_checkpoints/\u001b[m\n",
      "\t\u001b[31mMLOPs.ipynb\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
      "Enter passphrase for key '/home/ali/.ssh/id_ed25519': \n"
     ]
    }
   ],
   "source": [
    "! dvc push\n",
    "# ! dvc pull\n",
    "! git commit data/data.xml.dvc -m \"Dataset updates\"\n",
    "! git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0375a5ad-7733-43c3-bf87-9b49e93122c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to an specific version\n",
    "! git checkout 72de82ee151cae08636f90435be6709a8632ac96 # HEAD~1 data/data.xml.dvc # this line will checkout one of the git commits.\n",
    "! dvc checkout # and then dvc checkout makes sure that the data is correctly checked out.\n",
    "\n",
    "# After checking the data, to checkout to the last version of the data. use the following codes.\n",
    "! git checkout main  # or whatever branch you were on\n",
    "! dvc checkout  # to restore the latest version of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9268c7b1-eb37-4f88-a711-cff209c3ecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following after data modification.\n",
    "! dvc add data.xml\n",
    "! git add data.xml.dvc .gitignore\n",
    "! git commit -m 'test the data change'\n",
    "! dvc push\n",
    "! git push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83675f1-fc27-4f7e-82ab-7ac43772a5c2",
   "metadata": {},
   "source": [
    "***2- Data Quality Assurance:***\n",
    "***\n",
    "**2-1- Handling Missing Data and Time Zone Alignment:**<br>\n",
    "Imputation: We use mean, median, or forward filling based on historical data for numerical fields like SpotPriceDKK or SpotPurchase. <br>\n",
    "Data Exclusion: If certain columns are irrelevant for specific models, they can be excluded from training.\n",
    "Time Zone Alignment: We standardize all timestamps to DK using Pandas, ensuring consistent data input for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76023125-30e8-450f-adac-10498679e340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data from excel and showing the info about whole data\n",
    "import pandas as pd\n",
    "\n",
    "data_path= './data/NordPoolMarket.xlsx'\n",
    "raw_data= pd.read_excel(data_path)\n",
    "missing_values= raw_data.isnull()\n",
    "missing_counts= missing_values.sum() \n",
    "row_with_missing_values= raw_data[raw_data.isnull().any(axis=1)]\n",
    "print('A summary about dataset')\n",
    "print(raw_data.info())\n",
    "print('Missing values in the dataset')\n",
    "print(missing_values)\n",
    "print('The number of missing values in the dataset')\n",
    "print(missing_counts)\n",
    "print('Rows with the missing values')\n",
    "print(row_with_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c3aafc-befe-4cc2-b2be-c8c2fb70ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_1= raw_data.drop(columns='HourUTC') # removing UTC time to proceed just with DK time.\n",
    "# Fill in the missing values using interpolation for elbas datas and mean for others.\n",
    "raw_data_1['ElbasAveragePriceDKK']= raw_data_1['ElbasAveragePriceDKK'].interpolate(method='linear') \n",
    "raw_data_1['ElbasMaxPriceDKK']= raw_data_1['ElbasMaxPriceDKK'].interpolate(method='linear') \n",
    "raw_data_1['ElbasMinPriceDKK']= raw_data_1['ElbasMinPriceDKK'].interpolate(method='linear')\n",
    "raw_data_1['ElbasAveragePriceEUR']= raw_data_1['ElbasAveragePriceEUR'].interpolate(method='linear') \n",
    "raw_data_1['ElbasMaxPriceEUR']= raw_data_1['ElbasMaxPriceEUR'].interpolate(method='linear') \n",
    "raw_data_1['ElbasMinPriceEUR']= raw_data_1['ElbasMinPriceEUR'].interpolate(method='linear')\n",
    "print(raw_data_1.isnull().sum())\n",
    "# We can see that there are still nul cells in the dataframe\n",
    "raw_data_1= raw_data_1.drop([0,1]) # removing the first 2 rows because they don't have value\n",
    "print(raw_data_1.isnull().sum())\n",
    "\n",
    "# Save the modified excel file with modified added to the end.\n",
    "revised_path= data_path[:-4]+'modified'+'.xlsx'\n",
    "raw_data_1.to_excel(revised_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32518fc5-e4ce-465d-b972-2c58256ef71b",
   "metadata": {},
   "source": [
    "**2-1- Great Expectation Check:**\n",
    "***\n",
    "With Great Expectations, we can define different metrics to be assessed automatically in the pipeline. The pipeline includes the validation of data formats, ensuring the data integrity, and checking the compliance with schema requirements before training the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a846cbb-ff45-4249-9a7b-a222c98b1f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-25T14:25:42+0200 - INFO - FileDataContext loading fluent config\n",
      "2024-10-25T14:25:42+0200 - INFO - Loading 'datasources' ->\n",
      "[{'name': 'default_pandas_datasource', 'type': 'pandas'}]\n",
      "2024-10-25T14:25:42+0200 - INFO - Of 1 entries, no 'datasources' could be loaded\n",
      "2024-10-25T14:25:42+0200 - INFO - Saving 1 Fluent Datasources to /home/ali/NPEMF/gx/great_expectations.yml\n",
      "2024-10-25T14:25:42+0200 - INFO - PandasDatasource.dict() - missing `config_provider`, skipping config substitution\n",
      "2024-10-25T14:25:42+0200 - INFO - Saving 1 Fluent Datasources to /home/ali/NPEMF/gx/great_expectations.yml\n",
      "2024-10-25T14:25:42+0200 - INFO - ExcelAsset.dict() - missing `config_provider`, skipping config substitution\n",
      "2024-10-25T14:25:42+0200 - INFO - PandasDatasource.dict() - missing `config_provider`, skipping config substitution\n",
      "Loaded ExpectationSuite \"Energy Data Analysis\" containing 0 expectations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8abe25acc2b4dc0811444fedb0d7ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-25T14:25:51+0200 - INFO - \t1 expectation(s) included in expectation_suite.\n",
      "2024-10-25T14:25:59+0200 - INFO - \t1 expectation(s) included in expectation_suite.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0542dc84184660a3873dfea93d9b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"expectation_suite_name\": \"Energy Data Analysis\",\n",
      "  \"ge_cloud_id\": null,\n",
      "  \"expectations\": [],\n",
      "  \"data_asset_type\": null,\n",
      "  \"meta\": {\n",
      "    \"great_expectations_version\": \"0.18.19\"\n",
      "  }\n",
      "}\n",
      "Open this URL in your browser to view data docs: file://wsl.localhost/Debian/home/ali/NPEMF/gx/uncommitted/data_docs/local_site/index.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import great_expectations as gx\n",
    "import great_expectations.jupyter_ux\n",
    "from great_expectations.core.expectation_configuration import ExpectationConfiguration\n",
    "from great_expectations.data_context.types.resource_identifiers import ExpectationSuiteIdentifier\n",
    "from great_expectations.exceptions import DataContextError\n",
    "\n",
    "context = gx.get_context()\n",
    "# context= context.convert_to_file_context()\n",
    "validator= context.sources.pandas_default.read_excel(data_path)\n",
    "\n",
    "expectation_suite_name = \"Energy Data Analysis\"\n",
    "try:\n",
    "    suite = context.get_expectation_suite(expectation_suite_name=expectation_suite_name)\n",
    "    print(f'Loaded ExpectationSuite \"{suite.expectation_suite_name}\" containing {len(suite.expectations)} expectations.')\n",
    "except DataContextError:\n",
    "    suite = context.add_expectation_suite(expectation_suite_name=expectation_suite_name)\n",
    "    print(f'Created ExpectationSuite \"{suite.expectation_suite_name}\".')\n",
    "\n",
    "validator.expect_column_values_to_be_between(column='ElbasMinPriceEUR', min_value= 1,\n",
    "                                            max_value=10)\n",
    "validator.save_expectation_suite(discard_failed_expectations=False)\n",
    "checkpoint = context.add_or_update_checkpoint(\n",
    "    name=expectation_suite_name,\n",
    "    validator=validator)\n",
    "checkpoint_result = checkpoint.run()\n",
    "context.view_validation_result(checkpoint_result)\n",
    "# context.build_data_docs()\n",
    "# docs_path = context.get_docs_sites_urls()[0]['site_url']\n",
    "# print(f\"Open this URL in your browser to view data docs: {docs_path}\")\n",
    "# context.open_data_docs()\n",
    "\n",
    "print(context.get_expectation_suite(expectation_suite_name=expectation_suite_name))\n",
    "context.add_or_update_expectation_suite(expectation_suite=suite)\n",
    "\n",
    "suite_identifier = ExpectationSuiteIdentifier(expectation_suite_name=expectation_suite_name)\n",
    "context.build_data_docs(resource_identifiers=[suite_identifier])\n",
    "docs_path = context.get_docs_sites_urls()[0]['site_url']\n",
    "print(f\"Open this URL in your browser to view data docs: {docs_path[:7]+'wsl.localhost/Debian'+docs_path[7:]}\")\n",
    "context.open_data_docs(resource_identifier=suite_identifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
